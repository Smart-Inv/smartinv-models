{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset.csv')\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_products(df):\n",
    "    product_counts = df[\"nombre_producto\"].value_counts()\n",
    "    print(f\"Total number of products is: {len(product_counts)}\")\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    product_counts.plot(kind='bar')\n",
    "    \n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.xlabel(\"Nombre del Producto\")\n",
    "    plt.ylabel(\"Cantidad\")\n",
    "    plt.title(\"Productos de tienda Dummy\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_products_categories(df):\n",
    "    product_counts = df[\"categoria\"].value_counts()\n",
    "    print(f\"Total number of products categories is: {len(product_counts)}\")\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    product_counts.plot(kind='bar')\n",
    "    \n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.xlabel(\"Categoría\")\n",
    "    plt.ylabel(\"Cantidad\")\n",
    "    plt.title(\"Categorías de productos de tienda Dummy\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_products(df)\n",
    "plot_products_categories(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "Por cantidad no se refiere a stock total, sino las veces que aparece en el .csv dicho producto (como fila).\n",
    "\n",
    "5 categorías, especial incapie en deportivas y botas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"producto_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "No se puede ver la evolución del stock, ni de las unidades vendidas ni del precio. Vamos a tirar por ahí."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_stock_variations(df, productos=None):\n",
    "    df[\"fecha\"] = pd.to_datetime(df[\"fecha\"])\n",
    "\n",
    "    if productos is None:\n",
    "        productos_disponibles = df[\"nombre_producto\"].unique()\n",
    "        raise ValueError(f\"No se especificaron productos.\\nProductos disponibles: {productos_disponibles}\")\n",
    "\n",
    "    if isinstance(productos, str):\n",
    "        productos = [productos]\n",
    "\n",
    "    for producto in productos:\n",
    "        df_prod = df[df[\"nombre_producto\"] == producto]\n",
    "        \n",
    "        # Agrupamos por fecha para asegurarnos de no tener múltiples valores por mes\n",
    "        df_prod = df_prod.groupby(\"fecha\")[[\"stock_inicial\", \"stock_final\"]].sum().reset_index()\n",
    "\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        plt.plot(df_prod[\"fecha\"], df_prod[\"stock_inicial\"], label=\"Stock Inicial\", linestyle=\"--\")\n",
    "        plt.plot(df_prod[\"fecha\"], df_prod[\"stock_final\"], label=\"Stock Final\", linestyle=\"-\")\n",
    "\n",
    "        plt.title(f\"Evolución del Stock - {producto}\")\n",
    "        plt.xlabel(\"Fecha\")\n",
    "        plt.ylabel(\"Unidades en Stock\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stock_variations(df, productos=list(df[\"nombre_producto\"].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "Al ser un dataset sintético, no vemos problemas. Casi siempre hay un excedente de stock, pero podemos ver en qué meses y para qué productos hemos vendido todo el stock en dicho mes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Correlaciones\n",
    "\n",
    "Tendríamos que ver las correlaciones que hay entre ciertas variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_correlations(df):   \n",
    "    numerical_variables = df.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "    # Calculate correlation matrices for train_data and test_data\n",
    "    corr_train = df[numerical_variables].corr()\n",
    "    \n",
    "    # Create masks for the upper triangle\n",
    "    mask_train = np.triu(np.ones_like(corr_train, dtype=bool))\n",
    "    \n",
    "    # Set the text size and rotation\n",
    "    annot_kws = {\"size\": 8, \"rotation\": 45}\n",
    "    \n",
    "    # Generate heatmaps for train_data\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    ax_train = sns.heatmap(corr_train, mask=mask_train, cmap='viridis', annot=True,\n",
    "                          square=True, linewidths=.5, xticklabels=1, yticklabels=1, annot_kws=annot_kws)\n",
    "    plt.title('Correlation Heatmap - Train Data')\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Show the plots\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlations(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "Podemos sacar conclusiones lógicas:\n",
    "\n",
    "1. Si el stock final es grande, las unidades vendidas son bajas, por lo que se estima que no hace falta renovar en exceso el stock\n",
    "2. Si no se ha repuesto este mes, significa que las unidades vendidas no han sido muy altas\n",
    "3. Existe una relación curiosa con stock_final, reposicion_este_mes y stock_inicial. Correlación positiva.\n",
    "4. Si hay una promoción o un evento especial (asumiendo que este sea positivo para el negocio), las ventas crecen.\n",
    "5. Si te has quedado sin stock durante un mes, es más probable que repongas para el próximo.altas\n",
    "\n",
    "**IMPORTANTE**\n",
    "\n",
    "Nuestra `Y_pred` = reponer_proximo_mes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## Estacionalidad\n",
    "\n",
    "Es un modelo de predicción, es importante discernir entre estaciones del año. Tenemos:\n",
    "- Invierno (Diciembre-Febrero)\n",
    "- Primavera (Marzo-Mayo)\n",
    "- Verano (Junio-Agosto)\n",
    "- Otoño (Septiembre-Noviembre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = {\n",
    "    \"winter\": [12, 1, 2], \n",
    "    \"spring\": [3, 4, 5], \n",
    "    \"summer\": [6, 7, 8], \n",
    "    \"autumn\": [9, 10, 11]}\n",
    "\n",
    "def add_stations(df):\n",
    "    def get_station(mes):\n",
    "        for estacion, meses in stations.items():\n",
    "            if mes in meses:\n",
    "                return estacion\n",
    "        return \"desconocido\" # empty value\n",
    "\n",
    "    df[\"estacion\"] = df[\"mes\"].apply(get_station)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = add_stations(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "Importante destacar que el modelo no entiende caracteres, sino números. Tenemos que hacer un `encoding`.\n",
    "\n",
    "- OneHot-encoding: es lo que tenemos que hacer\n",
    "- Label Encoding: puede ir bien, pero puede añadir un orden artificial. No interesa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_into_onehot(df, columns):\n",
    "    dummies = pd.get_dummies(df[columns], prefix=columns).astype(int)\n",
    "    df = df.drop(columns=columns)\n",
    "    df = df.join(dummies)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = convert_into_onehot(df, [\"estacion\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"fecha\"] = pd.to_datetime(df[\"fecha\"])\n",
    "# se podría hacer day_of_the_week, is_weekend, trimetre... pero nuestro dataset no tiene esos datos\n",
    "df = df.drop(columns=[\"fecha\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlations(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "## Procesamiento de los productos \n",
    "\n",
    "De la misma manera, tenemos que convertir los productos y sus categorias con el One Hot Encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = convert_into_onehot(df, [\"nombre_producto\", \"categoria\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "## Modelo Predictivo\n",
    "\n",
    "Al trabajar con una Time-Series peculiar, se me ocurren varias cosas que probar:\n",
    "\n",
    "- Modelos de regresión continua, generan porcentajes y se aproximan. XGBoostRegressor, RandomForestRegressor, LinearRegression\n",
    "- Regresión Poisson. Se cumplen las condiciones `x>=0` y clases en rangos `1-5, 6-10...`. PoissonRegressor\n",
    "- Redes Neuronales, aunque no son la opción más preferida.\n",
    "\n",
    "Se usará cross-validation (CV) para mejorar la accuracy y comprobar que no haya overfitting.\n",
    "\n",
    "### Medición de errores\n",
    "\n",
    "Nuestra medición de errores no es binaria, sino que tenemos un número y buscamos aproximarnos lo más posible a él.\n",
    "- MAE (Mean Absolute Error) → media de los errores absolutos (muy interpretables).\n",
    "- RMSE (Root Mean Squared Error) → penaliza más los errores grandes -> podría ser interesante para ser especialmente crítico con los errores.\n",
    "- MAPE (Mean Absolute Percentage Error) → porcentaje de error, útil si las magnitudes varían mucho.\n",
    "- R² Score (coeficiente de determinación) → qué porcentaje de la varianza se explica."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "### Data Spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df[\"reposicion_este_mes\"]\n",
    "X = df.drop(columns=[\"reposicion_este_mes\"])\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "### Modelos de regresión continua"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "#### XGBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import pandas as pd\n",
    "\n",
    "scalers = [MinMaxScaler, RobustScaler, StandardScaler]\n",
    "n_estimators = [10, 12, 14, 16, 18, 20]\n",
    "max_depth = [10, 12, 14, 16, 18, 20]\n",
    "\n",
    "pipel = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('model', XGBRegressor())\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'scaler': [scaler() for scaler in scalers],\n",
    "    'model__n_estimators': n_estimators,\n",
    "    'model__max_depth': max_depth,\n",
    "}\n",
    "\n",
    "scoring = {\n",
    "    'r2': 'r2',\n",
    "    'neg_mse': 'neg_mean_squared_error',\n",
    "    'neg_mae': 'neg_mean_absolute_error'\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    pipel,\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring=scoring,\n",
    "    refit='r2',\n",
    "    return_train_score=True,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "best_pipe = grid.best_estimator_\n",
    "best_acc = grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = pd.DataFrame(grid.cv_results_)\n",
    "\n",
    "results = results[[\n",
    "    'param_scaler',\n",
    "    'param_model__n_estimators',\n",
    "    'param_model__max_depth',\n",
    "    'mean_test_r2',\n",
    "    'mean_test_neg_mse',\n",
    "    'mean_test_neg_mae'\n",
    "]]\n",
    "\n",
    "# invert so it is possible to study the error\n",
    "results['mean_test_mse'] = -results['mean_test_neg_mse']\n",
    "results['mean_test_mae'] = -results['mean_test_neg_mae']\n",
    "\n",
    "results = results.drop(columns=[\"mean_test_neg_mse\", \"mean_test_neg_mae\"])\n",
    "\n",
    "# best r^2\n",
    "results_sorted = results.sort_values(by='mean_test_r2', ascending=False)\n",
    "\n",
    "results_sorted.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "Tenemos errores muy pequeños, cercanos al 0.11 y 0.18 respectivamente. Por el momento, plantearemos la demo con este modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Guardar el mejor pipeline entrenado\n",
    "joblib.dump(best_pipe, 'xgboosterDemo.pkl')\n",
    "print(\"Modelo guardado como xgboosterDemo.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
